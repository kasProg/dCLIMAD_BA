{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6316197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add parent directory to sys.path (this is your project root)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas as gpd\n",
    "from esda.moran import Moran\n",
    "from libpysal.weights import KNN\n",
    "from eval.metrics import *\n",
    "from eval.plot import *\n",
    "import data.valid_crd as valid_crd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22ee5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end date\n",
    "clim = 'access_cm2'\n",
    "ref = 'gfdl_esm4'\n",
    "start_date = \"1981-01-01\"\n",
    "end_date = \"1995-12-31\"\n",
    "period = [2075, 2099]\n",
    "degree = 1\n",
    "testep = 20\n",
    "emph_quantile = 0.9\n",
    "scenario = 'ssp5_8_5'\n",
    "\n",
    "cmip6_dir = '/pscratch/sd/k/kas7897/cmip6'\n",
    "ref_path = '/pscratch/sd/k/kas7897/cmip6/gfdl_esm4'\n",
    "if clim ==  'ensemble':\n",
    "    y_clim = 'access_cm2'\n",
    "else:\n",
    "    y_clim = clim\n",
    "\n",
    "ds_sample = xr.open_dataset(f\"{cmip6_dir}/{y_clim}/historical/precipitation//clipped_US.nc\")\n",
    "valid_coords = valid_crd.valid_lat_lon(ds_sample, var_name='pr')\n",
    "\n",
    "\n",
    "y = torch.load(f'/pscratch/sd/k/kas7897/diffDownscale/jobs/{clim}-{ref}/QM_ANN_layers4_degree{degree}_quantile{emph_quantile}/all/1950_1980/{scenario}_{period[0]}_{period[1]}/y.pt', weights_only = False).to('cpu').squeeze(-1).numpy()\n",
    "x = torch.load(f'/pscratch/sd/k/kas7897/diffDownscale/jobs/{clim}-{ref}/QM_ANN_layers4_degree{degree}_quantile{emph_quantile}/all/1950_1980/{scenario}_{period[0]}_{period[1]}/x.pt', weights_only = False).to('cpu').squeeze(-1).numpy()\n",
    "time = torch.load(f'/pscratch/sd/k/kas7897/diffDownscale/jobs/{clim}-{ref}/QM_ANN_layers4_degree{degree}_quantile{emph_quantile}/all/1950_1980/{scenario}_{period[0]}_{period[1]}/time.pt', weights_only = False)\n",
    "time_y = torch.load(f'/pscratch/sd/k/kas7897/diffDownscale/jobs/{clim}-{ref}/QM_ANN_layers4_degree{degree}_quantile{emph_quantile}/all/1950_1980/{scenario}_{period[0]}_{period[1]}/time_y.pt', weights_only = False)\n",
    "\n",
    "\n",
    "xt = torch.load(f'/pscratch/sd/k/kas7897/diffDownscale/jobs/{clim}-{ref}/QM_ANN_layers4_degree{degree}_quantile{emph_quantile}/all/1950_1980/{scenario}_{period[0]}_{period[1]}/ep{testep}/xt.pt', weights_only = False)\n",
    "# xt = xr.open_dataset(f'/pscratch/sd/k/kas7897/cmip6/ensemble/1950_1980/{period[0]}_{period[1]}/diffDownscale/precipitation/ensemble.nc')\n",
    "# xt = xt['pr'].sel(lat=xr.DataArray(valid_coords[:, 0], dims='points'),\n",
    "#                                     lon=xr.DataArray(valid_coords[:, 1], dims='points'),\n",
    "#                                     method='nearest').values\n",
    "\n",
    "\n",
    "loca = xr.open_dataset(f'{cmip6_dir}/{clim}/{scenario}/precipitation/loca/coarse_USclip.nc')\n",
    "loca = loca['pr'].sel(lat=xr.DataArray(valid_coords[:, 0], dims='points'),\n",
    "                                    lon=xr.DataArray(valid_coords[:, 1], dims='points'),\n",
    "                                    method='nearest')\n",
    "loca = loca.sel(time =slice(f'{period[0]}', f'{period[1]}')).values\n",
    "\n",
    "#unit conversion\n",
    "loca = loca*86400\n",
    "\n",
    "\n",
    "QM_bench = f'/pscratch/sd/k/kas7897/diffDownscale/benchmark/QuantileMapping/conus/{clim}-{ref}/[1950, 1980]_{scenario}_{period}.pt'\n",
    "QM_debiased = torch.load(QM_bench, weights_only=False).squeeze(-1)\n",
    "QM_debiased = QM_debiased*86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6c92d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this block filters 'y' based on 'x' calender\n",
    "\n",
    "x_time_np = np.array([pd.Timestamp(str(t)) for t in time])\n",
    "x_time_np = np.array([pd.Timestamp(t).replace(hour=0, minute=0, second=0) for t in x_time_np], dtype='datetime64[D]')\n",
    "\n",
    "y_time_np = np.array([pd.Timestamp(str(t)) for t in time_y])\n",
    "y_time_np = np.array([pd.Timestamp(t).replace(hour=0, minute=0, second=0) for t in y_time_np], dtype='datetime64[D]')\n",
    "\n",
    "\n",
    "# Find commonindices where observed time matches model time\n",
    "common_times, y_idx, x_idx = np.intersect1d(y_time_np, x_time_np, return_indices=True)\n",
    "\n",
    "y = y[y_idx,:]\n",
    "x = x[x_idx,:]\n",
    "xt = xt[x_idx,:]\n",
    "loca = loca[x_idx,:]\n",
    "QM_debiased = QM_debiased[x_idx,:]\n",
    "\n",
    "x_time_np = x_time_np[x_idx]\n",
    "y_time_np = y_time_np[y_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fcfd75",
   "metadata": {},
   "source": [
    "### Season Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32dcd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = load_seasonal_data(y_time_np, y)\n",
    "x_s = load_seasonal_data(x_time_np, x)\n",
    "xt_s = load_seasonal_data(x_time_np, xt)\n",
    "\n",
    "loca_s = load_seasonal_data(x_time_np, loca)\n",
    "# QM_s = load_seasonal_data(x_time_np, QM_debiased)\n",
    "\n",
    "\n",
    "t_s = load_seasonal_data(x_time_np, x_time_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832cd88a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClimateIndices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize climate indices manager\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m climate_indices \u001b[38;5;241m=\u001b[39m \u001b[43mClimateIndices\u001b[49m()\n\u001b[1;32m      4\u001b[0m day_bias_percentages \u001b[38;5;241m=\u001b[39m get_day_bias_percentages(x, y, xt, climate_indices)\n\u001b[1;32m      5\u001b[0m mean_bias_percentages \u001b[38;5;241m=\u001b[39m get_mean_bias_percentages(x, y, xt, x_time_np, climate_indices)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ClimateIndices' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize climate indices manager\n",
    "climate_indices = ClimateIndices()\n",
    "\n",
    "day_bias_percentages = get_day_bias_percentages(x, y, xt, climate_indices)\n",
    "mean_bias_percentages = get_mean_bias_percentages(x, y, xt, x_time_np, climate_indices)\n",
    "\n",
    "loca_day_bias_percentages = get_day_bias_percentages(x, y, loca, climate_indices)\n",
    "loca_mean_bias_percentages = get_mean_bias_percentages(x, y, loca, x_time_np, climate_indices)\n",
    "\n",
    "\n",
    "QM_day_bias_percentages = get_day_bias_percentages(x, y, QM_debiased, climate_indices)\n",
    "QM_mean_bias_percentages = get_mean_bias_percentages(x, y, QM_debiased, x_time_np, climate_indices)\n",
    "\n",
    "## Arranging delCLIMAD and LOCA in one dictionary\n",
    "for key in day_bias_percentages.keys():\n",
    "    day_bias_percentages[key] = day_bias_percentages[key] + (loca_day_bias_percentages[key][1],) + (QM_day_bias_percentages[key][1],)\n",
    "\n",
    "\n",
    "for key in mean_bias_percentages.keys():\n",
    "    mean_bias_percentages[key] = mean_bias_percentages[key] + (loca_mean_bias_percentages[key][1],) + (QM_mean_bias_percentages[key][1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38103a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['SDII (Monthly)','CDD (Yearly)', 'CWD (Yearly)', \"Rx1day\", \"Rx5day\", \"R10mm\",  \"R20mm\", \"R95pTOT\", \"R99pTOT\"]\n",
    "d = dict(filter(lambda item: item[0] in keys , mean_bias_percentages.items()))\n",
    "\n",
    "keys = [\"Dry Days\", \"Wet Days >1mm\", \"Very Wet Days >10mm\", \"Very Very Wet Days >20mm\"]\n",
    "d4 = dict(filter(lambda item: item[0] in keys , day_bias_percentages.items()))\n",
    "\n",
    "# Create a 2x2 subplot figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(24, 12), sharey=True)\n",
    "\n",
    "# Ensure axes is flattened for easy indexing\n",
    "axes = axes.flatten()\n",
    "method_names = [f\"delCLIMAD-BA(degree{degree}_quantile{emph_quantile}_ep{testep})\", \"LOCA\"]\n",
    "\n",
    "\n",
    "# Call the function for each dataset\n",
    "plot_violin_bias(axes[0], d, \"Bias(%)\", \"Mean Bias(%) for Different Precipitation Indices\",  method_names=method_names, remove_outlier=True)\n",
    "\n",
    "plot_violin_bias(axes[1], d4, \"Bias(%)\", \"Day Bias(%) for Different Precipitation Indices\",  method_names=method_names, remove_outlier=True)\n",
    "fig.suptitle(f'{clim}', fontsize=20, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
