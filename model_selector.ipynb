{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f045c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfdd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bias_metrics_from_tensorboard(root_dir):\n",
    "    \"\"\"\n",
    "    Scans root_dir recursively, finds latest TensorBoard event file for each run,\n",
    "    loads scalar bias metrics, pivots them by step, and removes training loss and wet-day related tags.\n",
    "\n",
    "    Returns:\n",
    "        grouped_dfs: dict of {run_id: pd.DataFrame}, pivoted by step with cleaned tags\n",
    "    \"\"\"\n",
    "    latest_event_files = {}\n",
    "\n",
    "    # Step 1: Find latest event file for each run\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        event_files = [f for f in files if f.startswith(\"events.out.tfevents\")]\n",
    "        if not event_files:\n",
    "            continue\n",
    "\n",
    "        run_id = os.path.basename(root)\n",
    "        full_paths = [os.path.join(root, f) for f in event_files]\n",
    "        latest_file = max(full_paths, key=os.path.getmtime)\n",
    "        latest_event_files[run_id] = latest_file\n",
    "\n",
    "    # Step 2: Load scalars from each file\n",
    "    run_data = defaultdict(list)\n",
    "\n",
    "    for run_id, event_path in latest_event_files.items():\n",
    "        try:\n",
    "            ea = event_accumulator.EventAccumulator(event_path)\n",
    "            ea.Reload()\n",
    "            for tag in ea.Tags().get('scalars', []):\n",
    "                for s in ea.Scalars(tag):\n",
    "                    run_data[run_id].append((tag, s.step, s.value))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load {event_path}: {e}\")\n",
    "\n",
    "    # Step 3: Convert to cleaned pivoted DataFrames\n",
    "    grouped_dfs = {}\n",
    "    drop_tags = {\n",
    "        'Loss/train',\n",
    "        'median_adjusted/Wet Days >1mm',\n",
    "        'median_adjusted/Very Wet Days >10mm',\n",
    "        'median_adjusted/Very Very Wet Days >20mm',\n",
    "        'median_adjusted/Dry Days'\n",
    "    }\n",
    "\n",
    "    for run_id, records in run_data.items():\n",
    "        df = pd.DataFrame(records, columns=[\"tag\", \"step\", \"value\"])\n",
    "        pivoted = df.pivot(index='step', columns='tag', values='value').sort_index()\n",
    "        pivoted = pivoted.drop(columns=[tag for tag in drop_tags if tag in pivoted.columns], errors='ignore')\n",
    "        grouped_dfs[run_id] = pivoted.dropna()\n",
    "\n",
    "    return grouped_dfs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9303d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"runs_revised/conus_gridmet_cnn/access_cm2-gridmet\"\n",
    "grouped_dfs = load_bias_metrics_from_tensorboard(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d05d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a0b8fd4c', 'ab2538cf', '08fb4524', '43705867', 'bfcdd469', 'd6a01914', '18e94be5', '2eba82c4', '4a89eced', '6aab0ccc', '759cef29', 'e91a39c1', '2bac29a2', '51cfede1', '92c02791', 'b3bdb62f', '73a5cbfa', '15950e27', '4f247c2c', 'fe95099e', 'b9905a36', '6dc6b33f', 'b2b3ea84', 'fe7cb7a4', 'e2ce595b']\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# base_dir = \"/pscratch/sd/k/kas7897/diffDownscale/jobs_revised_pca/access_cm2-gridmet\"\n",
    "# second_level_dirs = []\n",
    "\n",
    "# for root, dirs, files in os.walk(base_dir):\n",
    "#     # Only consider first-level subdirectories\n",
    "#     if os.path.abspath(root) == os.path.abspath(base_dir):\n",
    "#         for d in dirs:\n",
    "#             subdir = os.path.join(root, d)\n",
    "#             # List subdirectories inside each first-level subdirectory\n",
    "#             for sub_root, sub_dirs, sub_files in os.walk(subdir):\n",
    "#                 if os.path.abspath(sub_root) == os.path.abspath(subdir):\n",
    "#                     for sd in sub_dirs:\n",
    "#                         sd = sd[:8]\n",
    "#                         second_level_dirs.append(sd)\n",
    "#         break  # Only need to process the top level\n",
    "\n",
    "# print(second_level_dirs)\n",
    "\n",
    "# grouped_dfs = {k: v for k, v in grouped_dfs.items() if any(sub in k for sub in second_level_dirs)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b43503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tag</th>\n",
       "      <th>Loss/validation</th>\n",
       "      <th>median_adjusted/CDD (Yearly)</th>\n",
       "      <th>median_adjusted/CWD (Yearly)</th>\n",
       "      <th>median_adjusted/R10mm</th>\n",
       "      <th>median_adjusted/R20mm</th>\n",
       "      <th>median_adjusted/R95pTOT</th>\n",
       "      <th>median_adjusted/R99pTOT</th>\n",
       "      <th>median_adjusted/Rx1day</th>\n",
       "      <th>median_adjusted/Rx5day</th>\n",
       "      <th>median_adjusted/SDII (Monthly)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19458.689453</td>\n",
       "      <td>-7.190606</td>\n",
       "      <td>11.618481</td>\n",
       "      <td>172.647736</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>2312.738281</td>\n",
       "      <td>2312.738281</td>\n",
       "      <td>2275.392578</td>\n",
       "      <td>2083.965332</td>\n",
       "      <td>1271.777588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>296.030273</td>\n",
       "      <td>123.769463</td>\n",
       "      <td>-55.113121</td>\n",
       "      <td>-25.100586</td>\n",
       "      <td>7.898946</td>\n",
       "      <td>-17.154980</td>\n",
       "      <td>-17.154980</td>\n",
       "      <td>72.489929</td>\n",
       "      <td>42.600544</td>\n",
       "      <td>127.159988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>83.359314</td>\n",
       "      <td>761.545776</td>\n",
       "      <td>-86.889351</td>\n",
       "      <td>-98.000145</td>\n",
       "      <td>-99.074608</td>\n",
       "      <td>-95.373024</td>\n",
       "      <td>-95.373024</td>\n",
       "      <td>-90.816208</td>\n",
       "      <td>-92.650383</td>\n",
       "      <td>-83.032486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>55.154156</td>\n",
       "      <td>1190.998291</td>\n",
       "      <td>-98.571426</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-99.504242</td>\n",
       "      <td>-99.666145</td>\n",
       "      <td>-98.919708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>51.236343</td>\n",
       "      <td>1253.336182</td>\n",
       "      <td>-99.603172</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-99.956123</td>\n",
       "      <td>-99.976555</td>\n",
       "      <td>-99.906738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>30.533264</td>\n",
       "      <td>-64.312965</td>\n",
       "      <td>369.839844</td>\n",
       "      <td>-82.140617</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>4.382234</td>\n",
       "      <td>4.382234</td>\n",
       "      <td>-26.120935</td>\n",
       "      <td>15.688938</td>\n",
       "      <td>-51.944843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>13.804272</td>\n",
       "      <td>-10.167025</td>\n",
       "      <td>27.525837</td>\n",
       "      <td>2.498233</td>\n",
       "      <td>-77.833069</td>\n",
       "      <td>-13.489286</td>\n",
       "      <td>-13.489286</td>\n",
       "      <td>11.286108</td>\n",
       "      <td>38.667217</td>\n",
       "      <td>0.812907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>12.780326</td>\n",
       "      <td>-5.115696</td>\n",
       "      <td>13.935658</td>\n",
       "      <td>1.406875</td>\n",
       "      <td>-76.275917</td>\n",
       "      <td>-22.942089</td>\n",
       "      <td>-22.942089</td>\n",
       "      <td>6.728521</td>\n",
       "      <td>31.895960</td>\n",
       "      <td>2.800834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10.871817</td>\n",
       "      <td>-2.767333</td>\n",
       "      <td>2.185374</td>\n",
       "      <td>-3.519678</td>\n",
       "      <td>-54.340134</td>\n",
       "      <td>-23.396389</td>\n",
       "      <td>-23.396389</td>\n",
       "      <td>11.722526</td>\n",
       "      <td>26.634626</td>\n",
       "      <td>3.980069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7.983530</td>\n",
       "      <td>-3.148599</td>\n",
       "      <td>-9.832252</td>\n",
       "      <td>-6.080954</td>\n",
       "      <td>-22.738094</td>\n",
       "      <td>-14.517997</td>\n",
       "      <td>-14.517997</td>\n",
       "      <td>23.930775</td>\n",
       "      <td>28.268358</td>\n",
       "      <td>12.486053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.978892</td>\n",
       "      <td>-3.343392</td>\n",
       "      <td>-15.369898</td>\n",
       "      <td>-7.735389</td>\n",
       "      <td>-15.635396</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>37.063957</td>\n",
       "      <td>36.496967</td>\n",
       "      <td>18.626852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.647113</td>\n",
       "      <td>-5.574267</td>\n",
       "      <td>-17.528345</td>\n",
       "      <td>-5.387231</td>\n",
       "      <td>-11.245498</td>\n",
       "      <td>14.790894</td>\n",
       "      <td>14.790894</td>\n",
       "      <td>50.491524</td>\n",
       "      <td>46.171177</td>\n",
       "      <td>24.582436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.073852</td>\n",
       "      <td>3.163304</td>\n",
       "      <td>-10.194632</td>\n",
       "      <td>1.840840</td>\n",
       "      <td>-2.676543</td>\n",
       "      <td>19.949993</td>\n",
       "      <td>19.949993</td>\n",
       "      <td>56.388435</td>\n",
       "      <td>55.792885</td>\n",
       "      <td>31.698338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.673584</td>\n",
       "      <td>12.810872</td>\n",
       "      <td>8.945579</td>\n",
       "      <td>8.647517</td>\n",
       "      <td>5.664990</td>\n",
       "      <td>24.383217</td>\n",
       "      <td>24.383217</td>\n",
       "      <td>63.544609</td>\n",
       "      <td>69.631340</td>\n",
       "      <td>36.585762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3.367227</td>\n",
       "      <td>18.472366</td>\n",
       "      <td>18.571171</td>\n",
       "      <td>7.787807</td>\n",
       "      <td>9.128015</td>\n",
       "      <td>22.871258</td>\n",
       "      <td>22.871258</td>\n",
       "      <td>62.120094</td>\n",
       "      <td>71.641937</td>\n",
       "      <td>34.085964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3.232993</td>\n",
       "      <td>22.794973</td>\n",
       "      <td>17.016178</td>\n",
       "      <td>8.031011</td>\n",
       "      <td>11.231634</td>\n",
       "      <td>22.428104</td>\n",
       "      <td>22.428104</td>\n",
       "      <td>60.754944</td>\n",
       "      <td>68.265236</td>\n",
       "      <td>31.958536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3.121443</td>\n",
       "      <td>23.090687</td>\n",
       "      <td>14.314059</td>\n",
       "      <td>7.901971</td>\n",
       "      <td>8.594930</td>\n",
       "      <td>22.131992</td>\n",
       "      <td>22.131992</td>\n",
       "      <td>59.729752</td>\n",
       "      <td>69.428894</td>\n",
       "      <td>31.122080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3.082652</td>\n",
       "      <td>20.718288</td>\n",
       "      <td>6.254251</td>\n",
       "      <td>9.521033</td>\n",
       "      <td>10.558518</td>\n",
       "      <td>21.977436</td>\n",
       "      <td>21.977436</td>\n",
       "      <td>59.992920</td>\n",
       "      <td>68.447540</td>\n",
       "      <td>33.211006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3.035872</td>\n",
       "      <td>24.243639</td>\n",
       "      <td>10.085034</td>\n",
       "      <td>10.193503</td>\n",
       "      <td>11.345060</td>\n",
       "      <td>21.771317</td>\n",
       "      <td>21.771317</td>\n",
       "      <td>57.855377</td>\n",
       "      <td>70.877815</td>\n",
       "      <td>31.567663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3.112933</td>\n",
       "      <td>24.786911</td>\n",
       "      <td>8.648445</td>\n",
       "      <td>7.983902</td>\n",
       "      <td>4.310327</td>\n",
       "      <td>17.480019</td>\n",
       "      <td>17.480019</td>\n",
       "      <td>51.366024</td>\n",
       "      <td>64.444031</td>\n",
       "      <td>28.804995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.204607</td>\n",
       "      <td>26.431536</td>\n",
       "      <td>8.146258</td>\n",
       "      <td>5.258218</td>\n",
       "      <td>1.272016</td>\n",
       "      <td>14.081182</td>\n",
       "      <td>14.081182</td>\n",
       "      <td>50.581696</td>\n",
       "      <td>63.743206</td>\n",
       "      <td>27.589085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3.175077</td>\n",
       "      <td>30.545458</td>\n",
       "      <td>11.585498</td>\n",
       "      <td>4.197288</td>\n",
       "      <td>-2.842766</td>\n",
       "      <td>11.248035</td>\n",
       "      <td>11.248035</td>\n",
       "      <td>47.703209</td>\n",
       "      <td>62.376350</td>\n",
       "      <td>24.408934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3.512168</td>\n",
       "      <td>31.291721</td>\n",
       "      <td>5.232426</td>\n",
       "      <td>-1.333264</td>\n",
       "      <td>-8.804947</td>\n",
       "      <td>7.127992</td>\n",
       "      <td>7.127992</td>\n",
       "      <td>42.612709</td>\n",
       "      <td>54.649002</td>\n",
       "      <td>22.393665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>3.668212</td>\n",
       "      <td>30.881466</td>\n",
       "      <td>7.810374</td>\n",
       "      <td>-1.577988</td>\n",
       "      <td>-9.333333</td>\n",
       "      <td>5.655530</td>\n",
       "      <td>5.655530</td>\n",
       "      <td>39.966942</td>\n",
       "      <td>52.310692</td>\n",
       "      <td>21.341429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>3.644037</td>\n",
       "      <td>31.031319</td>\n",
       "      <td>5.378401</td>\n",
       "      <td>-4.119231</td>\n",
       "      <td>-11.740256</td>\n",
       "      <td>5.373422</td>\n",
       "      <td>5.373422</td>\n",
       "      <td>38.634209</td>\n",
       "      <td>50.579472</td>\n",
       "      <td>19.325565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>3.546802</td>\n",
       "      <td>32.222878</td>\n",
       "      <td>8.473639</td>\n",
       "      <td>-5.838543</td>\n",
       "      <td>-12.777778</td>\n",
       "      <td>6.019948</td>\n",
       "      <td>6.019948</td>\n",
       "      <td>38.775551</td>\n",
       "      <td>52.775143</td>\n",
       "      <td>17.893383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3.561285</td>\n",
       "      <td>30.995173</td>\n",
       "      <td>6.113945</td>\n",
       "      <td>-4.211584</td>\n",
       "      <td>-13.934191</td>\n",
       "      <td>5.234203</td>\n",
       "      <td>5.234203</td>\n",
       "      <td>37.100842</td>\n",
       "      <td>50.468559</td>\n",
       "      <td>18.474222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>3.600620</td>\n",
       "      <td>30.497215</td>\n",
       "      <td>9.208094</td>\n",
       "      <td>-4.344865</td>\n",
       "      <td>-12.540117</td>\n",
       "      <td>4.162575</td>\n",
       "      <td>4.162575</td>\n",
       "      <td>37.868752</td>\n",
       "      <td>51.582687</td>\n",
       "      <td>19.008568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3.730720</td>\n",
       "      <td>30.516066</td>\n",
       "      <td>7.937925</td>\n",
       "      <td>-4.552227</td>\n",
       "      <td>-13.705937</td>\n",
       "      <td>3.086612</td>\n",
       "      <td>3.086612</td>\n",
       "      <td>37.138172</td>\n",
       "      <td>50.969185</td>\n",
       "      <td>18.066196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3.610533</td>\n",
       "      <td>29.882685</td>\n",
       "      <td>8.690476</td>\n",
       "      <td>-4.631904</td>\n",
       "      <td>-12.593874</td>\n",
       "      <td>3.374488</td>\n",
       "      <td>3.374488</td>\n",
       "      <td>37.053909</td>\n",
       "      <td>50.750957</td>\n",
       "      <td>17.532627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>3.713984</td>\n",
       "      <td>27.362797</td>\n",
       "      <td>6.050170</td>\n",
       "      <td>-7.720585</td>\n",
       "      <td>-17.663414</td>\n",
       "      <td>1.966559</td>\n",
       "      <td>1.966559</td>\n",
       "      <td>34.300835</td>\n",
       "      <td>47.574696</td>\n",
       "      <td>15.557822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3.830467</td>\n",
       "      <td>27.332054</td>\n",
       "      <td>7.355442</td>\n",
       "      <td>-8.493130</td>\n",
       "      <td>-19.053259</td>\n",
       "      <td>1.688804</td>\n",
       "      <td>1.688804</td>\n",
       "      <td>30.964970</td>\n",
       "      <td>45.861061</td>\n",
       "      <td>14.671086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4.063141</td>\n",
       "      <td>27.648489</td>\n",
       "      <td>6.782563</td>\n",
       "      <td>-10.147659</td>\n",
       "      <td>-21.136364</td>\n",
       "      <td>-1.681554</td>\n",
       "      <td>-1.681554</td>\n",
       "      <td>29.995857</td>\n",
       "      <td>43.869373</td>\n",
       "      <td>13.831932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3.772076</td>\n",
       "      <td>27.029070</td>\n",
       "      <td>8.724490</td>\n",
       "      <td>-11.133574</td>\n",
       "      <td>-20.234291</td>\n",
       "      <td>0.546080</td>\n",
       "      <td>0.546080</td>\n",
       "      <td>30.981815</td>\n",
       "      <td>46.087151</td>\n",
       "      <td>12.069776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>3.786460</td>\n",
       "      <td>27.404087</td>\n",
       "      <td>6.758787</td>\n",
       "      <td>-10.006801</td>\n",
       "      <td>-20.324366</td>\n",
       "      <td>-1.502522</td>\n",
       "      <td>-1.502522</td>\n",
       "      <td>30.292675</td>\n",
       "      <td>45.888100</td>\n",
       "      <td>13.264141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3.515823</td>\n",
       "      <td>25.284758</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>-9.958421</td>\n",
       "      <td>-17.455544</td>\n",
       "      <td>2.738251</td>\n",
       "      <td>2.738251</td>\n",
       "      <td>33.625740</td>\n",
       "      <td>50.427246</td>\n",
       "      <td>13.616701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>3.655713</td>\n",
       "      <td>25.704443</td>\n",
       "      <td>9.592679</td>\n",
       "      <td>-9.352620</td>\n",
       "      <td>-17.288784</td>\n",
       "      <td>1.407297</td>\n",
       "      <td>1.407297</td>\n",
       "      <td>32.732639</td>\n",
       "      <td>47.268414</td>\n",
       "      <td>13.599380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3.654317</td>\n",
       "      <td>24.496378</td>\n",
       "      <td>7.831633</td>\n",
       "      <td>-9.608389</td>\n",
       "      <td>-17.592592</td>\n",
       "      <td>1.201038</td>\n",
       "      <td>1.201038</td>\n",
       "      <td>32.351189</td>\n",
       "      <td>47.684189</td>\n",
       "      <td>12.817418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>3.528629</td>\n",
       "      <td>26.142138</td>\n",
       "      <td>8.477057</td>\n",
       "      <td>-8.952860</td>\n",
       "      <td>-17.289143</td>\n",
       "      <td>1.651677</td>\n",
       "      <td>1.651677</td>\n",
       "      <td>34.278145</td>\n",
       "      <td>48.556973</td>\n",
       "      <td>14.392450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3.257866</td>\n",
       "      <td>22.899551</td>\n",
       "      <td>8.703231</td>\n",
       "      <td>-6.602188</td>\n",
       "      <td>-12.292337</td>\n",
       "      <td>6.073282</td>\n",
       "      <td>6.073282</td>\n",
       "      <td>38.063541</td>\n",
       "      <td>52.105995</td>\n",
       "      <td>16.327652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3.287210</td>\n",
       "      <td>23.078175</td>\n",
       "      <td>11.312795</td>\n",
       "      <td>-7.974289</td>\n",
       "      <td>-14.561072</td>\n",
       "      <td>5.395307</td>\n",
       "      <td>5.395307</td>\n",
       "      <td>37.031616</td>\n",
       "      <td>52.064556</td>\n",
       "      <td>15.126139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tag   Loss/validation  median_adjusted/CDD (Yearly)  \\\n",
       "step                                                  \n",
       "0        19458.689453                     -7.190606   \n",
       "10         296.030273                    123.769463   \n",
       "20          83.359314                    761.545776   \n",
       "30          55.154156                   1190.998291   \n",
       "40          51.236343                   1253.336182   \n",
       "50          30.533264                    -64.312965   \n",
       "60          13.804272                    -10.167025   \n",
       "70          12.780326                     -5.115696   \n",
       "80          10.871817                     -2.767333   \n",
       "90           7.983530                     -3.148599   \n",
       "100          5.978892                     -3.343392   \n",
       "110          4.647113                     -5.574267   \n",
       "120          4.073852                      3.163304   \n",
       "130          3.673584                     12.810872   \n",
       "140          3.367227                     18.472366   \n",
       "150          3.232993                     22.794973   \n",
       "160          3.121443                     23.090687   \n",
       "170          3.082652                     20.718288   \n",
       "180          3.035872                     24.243639   \n",
       "190          3.112933                     24.786911   \n",
       "200          3.204607                     26.431536   \n",
       "210          3.175077                     30.545458   \n",
       "220          3.512168                     31.291721   \n",
       "230          3.668212                     30.881466   \n",
       "240          3.644037                     31.031319   \n",
       "250          3.546802                     32.222878   \n",
       "260          3.561285                     30.995173   \n",
       "270          3.600620                     30.497215   \n",
       "280          3.730720                     30.516066   \n",
       "290          3.610533                     29.882685   \n",
       "300          3.713984                     27.362797   \n",
       "310          3.830467                     27.332054   \n",
       "320          4.063141                     27.648489   \n",
       "330          3.772076                     27.029070   \n",
       "340          3.786460                     27.404087   \n",
       "350          3.515823                     25.284758   \n",
       "360          3.655713                     25.704443   \n",
       "370          3.654317                     24.496378   \n",
       "380          3.528629                     26.142138   \n",
       "390          3.257866                     22.899551   \n",
       "400          3.287210                     23.078175   \n",
       "\n",
       "tag   median_adjusted/CWD (Yearly)  median_adjusted/R10mm  \\\n",
       "step                                                        \n",
       "0                        11.618481             172.647736   \n",
       "10                      -55.113121             -25.100586   \n",
       "20                      -86.889351             -98.000145   \n",
       "30                      -98.571426            -100.000000   \n",
       "40                      -99.603172            -100.000000   \n",
       "50                      369.839844             -82.140617   \n",
       "60                       27.525837               2.498233   \n",
       "70                       13.935658               1.406875   \n",
       "80                        2.185374              -3.519678   \n",
       "90                       -9.832252              -6.080954   \n",
       "100                     -15.369898              -7.735389   \n",
       "110                     -17.528345              -5.387231   \n",
       "120                     -10.194632               1.840840   \n",
       "130                       8.945579               8.647517   \n",
       "140                      18.571171               7.787807   \n",
       "150                      17.016178               8.031011   \n",
       "160                      14.314059               7.901971   \n",
       "170                       6.254251               9.521033   \n",
       "180                      10.085034              10.193503   \n",
       "190                       8.648445               7.983902   \n",
       "200                       8.146258               5.258218   \n",
       "210                      11.585498               4.197288   \n",
       "220                       5.232426              -1.333264   \n",
       "230                       7.810374              -1.577988   \n",
       "240                       5.378401              -4.119231   \n",
       "250                       8.473639              -5.838543   \n",
       "260                       6.113945              -4.211584   \n",
       "270                       9.208094              -4.344865   \n",
       "280                       7.937925              -4.552227   \n",
       "290                       8.690476              -4.631904   \n",
       "300                       6.050170              -7.720585   \n",
       "310                       7.355442              -8.493130   \n",
       "320                       6.782563             -10.147659   \n",
       "330                       8.724490             -11.133574   \n",
       "340                       6.758787             -10.006801   \n",
       "350                       9.166667              -9.958421   \n",
       "360                       9.592679              -9.352620   \n",
       "370                       7.831633              -9.608389   \n",
       "380                       8.477057              -8.952860   \n",
       "390                       8.703231              -6.602188   \n",
       "400                      11.312795              -7.974289   \n",
       "\n",
       "tag   median_adjusted/R20mm  median_adjusted/R95pTOT  median_adjusted/R99pTOT  \\\n",
       "step                                                                            \n",
       "0                550.000000              2312.738281              2312.738281   \n",
       "10                 7.898946               -17.154980               -17.154980   \n",
       "20               -99.074608               -95.373024               -95.373024   \n",
       "30              -100.000000              -100.000000              -100.000000   \n",
       "40              -100.000000              -100.000000              -100.000000   \n",
       "50              -100.000000                 4.382234                 4.382234   \n",
       "60               -77.833069               -13.489286               -13.489286   \n",
       "70               -76.275917               -22.942089               -22.942089   \n",
       "80               -54.340134               -23.396389               -23.396389   \n",
       "90               -22.738094               -14.517997               -14.517997   \n",
       "100              -15.635396                 0.310150                 0.310150   \n",
       "110              -11.245498                14.790894                14.790894   \n",
       "120               -2.676543                19.949993                19.949993   \n",
       "130                5.664990                24.383217                24.383217   \n",
       "140                9.128015                22.871258                22.871258   \n",
       "150               11.231634                22.428104                22.428104   \n",
       "160                8.594930                22.131992                22.131992   \n",
       "170               10.558518                21.977436                21.977436   \n",
       "180               11.345060                21.771317                21.771317   \n",
       "190                4.310327                17.480019                17.480019   \n",
       "200                1.272016                14.081182                14.081182   \n",
       "210               -2.842766                11.248035                11.248035   \n",
       "220               -8.804947                 7.127992                 7.127992   \n",
       "230               -9.333333                 5.655530                 5.655530   \n",
       "240              -11.740256                 5.373422                 5.373422   \n",
       "250              -12.777778                 6.019948                 6.019948   \n",
       "260              -13.934191                 5.234203                 5.234203   \n",
       "270              -12.540117                 4.162575                 4.162575   \n",
       "280              -13.705937                 3.086612                 3.086612   \n",
       "290              -12.593874                 3.374488                 3.374488   \n",
       "300              -17.663414                 1.966559                 1.966559   \n",
       "310              -19.053259                 1.688804                 1.688804   \n",
       "320              -21.136364                -1.681554                -1.681554   \n",
       "330              -20.234291                 0.546080                 0.546080   \n",
       "340              -20.324366                -1.502522                -1.502522   \n",
       "350              -17.455544                 2.738251                 2.738251   \n",
       "360              -17.288784                 1.407297                 1.407297   \n",
       "370              -17.592592                 1.201038                 1.201038   \n",
       "380              -17.289143                 1.651677                 1.651677   \n",
       "390              -12.292337                 6.073282                 6.073282   \n",
       "400              -14.561072                 5.395307                 5.395307   \n",
       "\n",
       "tag   median_adjusted/Rx1day  median_adjusted/Rx5day  \\\n",
       "step                                                   \n",
       "0                2275.392578             2083.965332   \n",
       "10                 72.489929               42.600544   \n",
       "20                -90.816208              -92.650383   \n",
       "30                -99.504242              -99.666145   \n",
       "40                -99.956123              -99.976555   \n",
       "50                -26.120935               15.688938   \n",
       "60                 11.286108               38.667217   \n",
       "70                  6.728521               31.895960   \n",
       "80                 11.722526               26.634626   \n",
       "90                 23.930775               28.268358   \n",
       "100                37.063957               36.496967   \n",
       "110                50.491524               46.171177   \n",
       "120                56.388435               55.792885   \n",
       "130                63.544609               69.631340   \n",
       "140                62.120094               71.641937   \n",
       "150                60.754944               68.265236   \n",
       "160                59.729752               69.428894   \n",
       "170                59.992920               68.447540   \n",
       "180                57.855377               70.877815   \n",
       "190                51.366024               64.444031   \n",
       "200                50.581696               63.743206   \n",
       "210                47.703209               62.376350   \n",
       "220                42.612709               54.649002   \n",
       "230                39.966942               52.310692   \n",
       "240                38.634209               50.579472   \n",
       "250                38.775551               52.775143   \n",
       "260                37.100842               50.468559   \n",
       "270                37.868752               51.582687   \n",
       "280                37.138172               50.969185   \n",
       "290                37.053909               50.750957   \n",
       "300                34.300835               47.574696   \n",
       "310                30.964970               45.861061   \n",
       "320                29.995857               43.869373   \n",
       "330                30.981815               46.087151   \n",
       "340                30.292675               45.888100   \n",
       "350                33.625740               50.427246   \n",
       "360                32.732639               47.268414   \n",
       "370                32.351189               47.684189   \n",
       "380                34.278145               48.556973   \n",
       "390                38.063541               52.105995   \n",
       "400                37.031616               52.064556   \n",
       "\n",
       "tag   median_adjusted/SDII (Monthly)  \n",
       "step                                  \n",
       "0                        1271.777588  \n",
       "10                        127.159988  \n",
       "20                        -83.032486  \n",
       "30                        -98.919708  \n",
       "40                        -99.906738  \n",
       "50                        -51.944843  \n",
       "60                          0.812907  \n",
       "70                          2.800834  \n",
       "80                          3.980069  \n",
       "90                         12.486053  \n",
       "100                        18.626852  \n",
       "110                        24.582436  \n",
       "120                        31.698338  \n",
       "130                        36.585762  \n",
       "140                        34.085964  \n",
       "150                        31.958536  \n",
       "160                        31.122080  \n",
       "170                        33.211006  \n",
       "180                        31.567663  \n",
       "190                        28.804995  \n",
       "200                        27.589085  \n",
       "210                        24.408934  \n",
       "220                        22.393665  \n",
       "230                        21.341429  \n",
       "240                        19.325565  \n",
       "250                        17.893383  \n",
       "260                        18.474222  \n",
       "270                        19.008568  \n",
       "280                        18.066196  \n",
       "290                        17.532627  \n",
       "300                        15.557822  \n",
       "310                        14.671086  \n",
       "320                        13.831932  \n",
       "330                        12.069776  \n",
       "340                        13.264141  \n",
       "350                        13.616701  \n",
       "360                        13.599380  \n",
       "370                        12.817418  \n",
       "380                        14.392450  \n",
       "390                        16.327652  \n",
       "400                        15.126139  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_dfs['4de68857_1979_2000_2001_2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1240bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir1 = \"runs_revised/conus_pca/access_cm2-gridmet\"\n",
    "# grouped_dfs_pca = load_bias_metrics_from_tensorboard(root_dir1)\n",
    "\n",
    "# grouped_dfs = grouped_dfs | grouped_dfs_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484ded37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_best_experiment_and_epoch(exp_dict, agg_method='median'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        exp_dict: dict of {exp_name: pd.DataFrame} with index=step, columns=indices (bias %)\n",
    "        agg_method: 'median', 'mean', or 'sum' to aggregate bias across indices\n",
    "    \n",
    "    Returns:\n",
    "        best_overall: (exp, step, score)\n",
    "        best_per_index: {index: (exp, step, bias)}\n",
    "        score_df: dataframe with all scores\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for exp, df in exp_dict.items():\n",
    "        for step, row in df.iterrows():\n",
    "            bias_vals = row.dropna()\n",
    "            if agg_method == 'median':\n",
    "                score = bias_vals.abs().median()\n",
    "            elif agg_method == 'mean':\n",
    "                score = bias_vals.abs().mean()\n",
    "            elif agg_method == 'sum':\n",
    "                score = bias_vals.abs().sum()\n",
    "            else:\n",
    "                raise ValueError(\"agg_method must be 'median', 'mean', or 'sum'\")\n",
    "\n",
    "            rows.append({\n",
    "                'exp': exp,\n",
    "                'step': step,\n",
    "                'score': score,\n",
    "                **row.to_dict()\n",
    "            })\n",
    "\n",
    "    score_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Best overall (lowest aggregated score)\n",
    "    best_overall_row = score_df.loc[score_df['score'].idxmin()]\n",
    "    best_overall = (best_overall_row['exp'], best_overall_row['step'], best_overall_row['score'])\n",
    "\n",
    "    # Best for each index (closest to 0 bias)\n",
    "    indices = [col for col in score_df.columns if col not in ['exp', 'step', 'score']]\n",
    "    best_per_index = {}\n",
    "    for ind in indices:\n",
    "        best_row = score_df.loc[score_df[ind].abs().idxmin()]\n",
    "        best_per_index[ind] = (best_row['exp'], best_row['step'], best_row[ind])\n",
    "\n",
    "    return best_overall, best_per_index, score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15780c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_overall, best_per_index, scores = find_best_experiment_and_epoch(grouped_dfs, agg_method='median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8175467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4de68857_1979_2000_2001_2014', 220, 7.9664692878723145)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eec61bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss/validation': ('40970740_1979_2000_2001_2014', 380, 2.3028457164764404),\n",
       " 'median_adjusted/CDD (Yearly)': ('74cc5d77_1979_2000_2001_2014',\n",
       "  30,\n",
       "  0.18543754518032074),\n",
       " 'median_adjusted/CWD (Yearly)': ('cd2c368c_1979_2000_2001_2014',\n",
       "  80,\n",
       "  -0.0371057502925396),\n",
       " 'median_adjusted/R10mm': ('cd2c368c_1979_2000_2001_2014',\n",
       "  70,\n",
       "  -0.5277726054191589),\n",
       " 'median_adjusted/R20mm': ('6816184f_1979_2000_2001_2014', 130, 0.0),\n",
       " 'median_adjusted/R95pTOT': ('74cc5d77_1979_2000_2001_2014',\n",
       "  250,\n",
       "  -0.13641822338104248),\n",
       " 'median_adjusted/R99pTOT': ('74cc5d77_1979_2000_2001_2014',\n",
       "  250,\n",
       "  -0.13641822338104248),\n",
       " 'median_adjusted/Rx1day': ('cd2c368c_1979_2000_2001_2014',\n",
       "  70,\n",
       "  5.9045257568359375),\n",
       " 'median_adjusted/Rx5day': ('40970740_1979_2000_2001_2014',\n",
       "  0,\n",
       "  3.2955329418182373),\n",
       " 'median_adjusted/SDII (Monthly)': ('4de68857_1979_2000_2001_2014',\n",
       "  60,\n",
       "  0.8129074573516846)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160c98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Index Counts Per Experiment:\n",
      "40970740_1979_2000_2001_2014: 2 indices\n",
      "74cc5d77_1979_2000_2001_2014: 3 indices\n",
      "cd2c368c_1979_2000_2001_2014: 3 indices\n",
      "6816184f_1979_2000_2001_2014: 1 indices\n",
      "4de68857_1979_2000_2001_2014: 1 indices\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_best_indices(best_per_index):\n",
    "    exp_counts = Counter()\n",
    "    for idx, (exp, step, bias) in best_per_index.items():\n",
    "        exp_counts[exp] += 1\n",
    "    return dict(exp_counts)\n",
    "\n",
    "counts = count_best_indices(best_per_index)\n",
    "print(\"üèÜ Best Index Counts Per Experiment:\")\n",
    "for exp, count in counts.items():\n",
    "    print(f\"{exp}: {count} indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_experiment_with_stability(exp_dict, agg_method='median', \n",
    "                                       stability_window=10, min_epochs=50,\n",
    "                                       loss_weight=0.3, bias_weight=0.7):\n",
    "    \"\"\"\n",
    "    Find best experiment considering both bias performance AND training stability.\n",
    "    \n",
    "    Args:\n",
    "        stability_window: number of recent epochs to check for stability\n",
    "        min_epochs: minimum training epochs before considering a model\n",
    "        loss_weight, bias_weight: relative importance of loss vs bias (should sum to 1)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for exp, df in exp_dict.items():\n",
    "        if len(df) < min_epochs:\n",
    "            continue\n",
    "            \n",
    "        # Get loss data (you'll need to load this separately)\n",
    "        loss_data = load_loss_data(exp)  # You'll need to implement this\n",
    "        \n",
    "        for step in df.index[min_epochs:]:  # Only consider after min_epochs\n",
    "            row = df.loc[step]\n",
    "            bias_vals = row.dropna()\n",
    "            \n",
    "            if len(bias_vals) == 0:\n",
    "                continue\n",
    "                \n",
    "            # 1. Calculate bias score\n",
    "            if agg_method == 'median':\n",
    "                bias_score = bias_vals.abs().median()\n",
    "            elif agg_method == 'mean':\n",
    "                bias_score = bias_vals.abs().mean()\n",
    "            else:\n",
    "                bias_score = bias_vals.abs().sum()\n",
    "            \n",
    "            # 2. Check training stability\n",
    "            stability_metrics = calculate_stability(loss_data, step, stability_window)\n",
    "            \n",
    "            # 3. Combined score\n",
    "            combined_score = (loss_weight * stability_metrics['loss_score'] + \n",
    "                            bias_weight * bias_score)\n",
    "            \n",
    "            results.append({\n",
    "                'exp': exp,\n",
    "                'step': step,\n",
    "                'bias_score': bias_score,\n",
    "                'loss_trend': stability_metrics['loss_trend'],\n",
    "                'loss_variance': stability_metrics['loss_variance'],\n",
    "                'is_stable': stability_metrics['is_stable'],\n",
    "                'epochs_since_improvement': stability_metrics['epochs_since_improvement'],\n",
    "                'combined_score': combined_score,\n",
    "                **row.to_dict()\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Filter to only stable models\n",
    "    stable_results = results_df[results_df['is_stable']].copy()\n",
    "    \n",
    "    if len(stable_results) == 0:\n",
    "        print(\"‚ö†Ô∏è No stable models found! Relaxing stability criteria...\")\n",
    "        stable_results = results_df\n",
    "    \n",
    "    # Best stable model\n",
    "    best_stable = stable_results.loc[stable_results['combined_score'].idxmin()]\n",
    "    \n",
    "    return best_stable, stable_results\n",
    "\n",
    "def calculate_stability(loss_data, current_step, window=10):\n",
    "    \"\"\"Calculate training stability metrics\"\"\"\n",
    "    if current_step < window:\n",
    "        return {'is_stable': False, 'loss_trend': float('inf'), \n",
    "                'loss_variance': float('inf'), 'loss_score': 1.0,\n",
    "                'epochs_since_improvement': 0}\n",
    "    \n",
    "    recent_loss = loss_data[current_step-window:current_step+1]\n",
    "    \n",
    "    # 1. Loss trend (should be flat or slightly decreasing)\n",
    "    loss_trend = np.polyfit(range(len(recent_loss)), recent_loss, 1)[0]\n",
    "    \n",
    "    # 2. Loss variance (should be low)\n",
    "    loss_variance = np.var(recent_loss)\n",
    "    \n",
    "    # 3. Epochs since last significant improvement\n",
    "    best_loss_idx = np.argmin(loss_data[:current_step+1])\n",
    "    epochs_since_improvement = current_step - best_loss_idx\n",
    "    \n",
    "    # 4. Stability criteria\n",
    "    is_stable = (\n",
    "        abs(loss_trend) < 0.001 and  # Trend is nearly flat\n",
    "        loss_variance < 0.01 and     # Low variance\n",
    "        epochs_since_improvement < window * 2  # Recent improvement\n",
    "    )\n",
    "    \n",
    "    # 5. Loss score (normalized, lower is better)\n",
    "    loss_score = min(recent_loss) / max(loss_data)  # Relative to worst loss\n",
    "    \n",
    "    return {\n",
    "        'is_stable': is_stable,\n",
    "        'loss_trend': loss_trend,\n",
    "        'loss_variance': loss_variance,\n",
    "        'loss_score': loss_score,\n",
    "        'epochs_since_improvement': epochs_since_improvement\n",
    "    }\n",
    "\n",
    "def load_loss_data(exp_name):\n",
    "    \"\"\"Load training loss for a specific experiment\"\"\"\n",
    "    # You'll need to implement this based on your TensorBoard data\n",
    "    # Return array of loss values by epoch\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_select.py\n",
    "import json, math, re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Any, Tuple, Optional\n",
    "\n",
    "############################\n",
    "# 1) Configurable settings #\n",
    "############################\n",
    "# Your metrics keys (all are \"lower is better\" AFTER transform in _compute_J)\n",
    "METRIC_WEIGHTS = {\n",
    "    \"pdf_gap\": 0.25,          # 1 - PDF overlap (we'll convert inside)\n",
    "    \"wasserstein\": 0.15,\n",
    "    \"tail_q95\": 0.10,\n",
    "    \"tail_q99\": 0.10,\n",
    "    \"tail_rx1\": 0.075,\n",
    "    \"tail_rx5\": 0.075,\n",
    "    \"wet_sdii\": 0.05,\n",
    "    \"wet_cdd\": 0.05,\n",
    "    \"wet_cwd\": 0.05,\n",
    "    \"wet_r10\": 0.05,\n",
    "    \"wet_r20\": 0.05,\n",
    "    \"trend_gap\": 0.10,\n",
    "}\n",
    "\n",
    "# Optionally weight across temporal aggregation scales\n",
    "SCALE_WEIGHTS = {\"daily\": 0.5, \"monthly\": 0.3, \"seasonal\": 0.2}\n",
    "\n",
    "EMA_ALPHA = 0.3            # smoothing for J across epochs\n",
    "MIN_EPOCHS = 10            # require at least this many epochs to evaluate a run\n",
    "IMPROVEMENT_FLOOR = 0.02   # require >=2% improvement vs the run's early J, else mark as \"stagnant\"\n",
    "NONINCR_TOL = 0.01         # allow tiny non-monotonicity (1%) in the tail of the curve\n",
    "\n",
    "# Filenames expected inside each trial directory\n",
    "VAL_LOG = \"val_metrics.jsonl\"    # one json per line: {\"epoch\": int, \"loss\": float, \"metrics\": {...}}\n",
    "BASELINE_FILE = \"baseline.json\"  # raw-vs-obs metrics dict used for normalization (same keys as metrics)\n",
    "\n",
    "#######################\n",
    "# 2) Helper utilities #\n",
    "#######################\n",
    "def _ema(series: List[float], alpha: float) -> List[float]:\n",
    "    out = []\n",
    "    s = None\n",
    "    for x in series:\n",
    "        s = x if s is None else alpha * x + (1 - alpha) * s\n",
    "        out.append(s)\n",
    "    return out\n",
    "\n",
    "def _safe_div(a: float, b: float, eps: float = 1e-8) -> float:\n",
    "    return a / (b + eps)\n",
    "\n",
    "def _normalize_metric(value: float, baseline: float, lower_better=True) -> float:\n",
    "    \"\"\"\n",
    "    Map metric to [0,1] where 0 ~ perfect, 1 ~ as bad as raw baseline.\n",
    "    If lower_better is False (e.g., PDF overlap), we invert appropriately.\n",
    "    \"\"\"\n",
    "    if not lower_better:\n",
    "        # convert to a \"gap\" first: 1 - overlap\n",
    "        value = 1.0 - value\n",
    "        baseline = 1.0 - baseline\n",
    "    # Normalize relative to baseline (clip to [0,1.5] but we'll clamp later)\n",
    "    norm = _safe_div(value, baseline if baseline > 0 else 1.0)\n",
    "    return max(0.0, min(1.0, norm))\n",
    "\n",
    "def _compute_J(metrics: Dict[str, float], baseline: Dict[str, float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute single scalar J from (possibly multi-scale) metrics.\n",
    "    Expect keys like \"daily/pdf_overlap\", \"monthly/rx1_err\", etc.\n",
    "    \"\"\"\n",
    "    accum = 0.0\n",
    "    wsum = 0.0\n",
    "    for scale, sw in SCALE_WEIGHTS.items():\n",
    "        scale_contrib = 0.0\n",
    "        scale_wsum = 0.0\n",
    "\n",
    "        # materialize a per-scale dict if present\n",
    "        def get(key_suffix: str) -> Optional[float]:\n",
    "            # prefer \"<scale>/<key>\", else plain \"<key>\"\n",
    "            if f\"{scale}/{key_suffix}\" in metrics:\n",
    "                return metrics[f\"{scale}/{key_suffix}\"]\n",
    "            return metrics.get(key_suffix, None)\n",
    "\n",
    "        # build normalized components\n",
    "        parts = {\n",
    "            \"pdf_gap\": _normalize_metric(\n",
    "                get(\"pdf_overlap\") if get(\"pdf_overlap\") is not None else 1.0,  # overlap in [0,1]\n",
    "                baseline.get(f\"{scale}/pdf_overlap\", baseline.get(\"pdf_overlap\", 0.0)),\n",
    "                lower_better=False\n",
    "            ),\n",
    "            \"wasserstein\": _normalize_metric(\n",
    "                get(\"wasserstein\") or 0.0,\n",
    "                baseline.get(f\"{scale}/wasserstein\", baseline.get(\"wasserstein\", 1.0)),\n",
    "                lower_better=True\n",
    "            ),\n",
    "            \"tail_q95\": _normalize_metric(get(\"q95_err\") or 0.0, baseline.get(f\"{scale}/q95_err\", 1.0)),\n",
    "            \"tail_q99\": _normalize_metric(get(\"q99_err\") or 0.0, baseline.get(f\"{scale}/q99_err\", 1.0)),\n",
    "            \"tail_rx1\": _normalize_metric(get(\"rx1_err\") or 0.0, baseline.get(f\"{scale}/rx1_err\", 1.0)),\n",
    "            \"tail_rx5\": _normalize_metric(get(\"rx5_err\") or 0.0, baseline.get(f\"{scale}/rx5_err\", 1.0)),\n",
    "            \"wet_sdii\": _normalize_metric(get(\"sdii_err\") or 0.0, baseline.get(f\"{scale}/sdii_err\", 1.0)),\n",
    "            \"wet_cdd\":  _normalize_metric(get(\"cdd_err\") or 0.0,  baseline.get(f\"{scale}/cdd_err\", 1.0)),\n",
    "            \"wet_cwd\":  _normalize_metric(get(\"cwd_err\") or 0.0,  baseline.get(f\"{scale}/cwd_err\", 1.0)),\n",
    "            \"wet_r10\":  _normalize_metric(get(\"r10_err\") or 0.0,  baseline.get(f\"{scale}/r10_err\", 1.0)),\n",
    "            \"wet_r20\":  _normalize_metric(get(\"r20_err\") or 0.0,  baseline.get(f\"{scale}/r20_err\", 1.0)),\n",
    "            \"trend_gap\": _normalize_metric(get(\"trend_gap\") or 0.0, baseline.get(f\"{scale}/trend_gap\", 1.0)),\n",
    "        }\n",
    "\n",
    "        for k, v in parts.items():\n",
    "            w = METRIC_WEIGHTS.get(k, 0.0)\n",
    "            scale_contrib += w * v\n",
    "            scale_wsum += w\n",
    "\n",
    "        if scale_wsum > 0:\n",
    "            accum += sw * (scale_contrib / scale_wsum)\n",
    "            wsum += sw\n",
    "\n",
    "    return accum / wsum if wsum > 0 else 1.0\n",
    "\n",
    "@dataclass\n",
    "class EpochEval:\n",
    "    epoch: int\n",
    "    loss: float\n",
    "    J: float\n",
    "    J_ema: float\n",
    "\n",
    "@dataclass\n",
    "class TrialResult:\n",
    "    trial_dir: str\n",
    "    best_epoch: int\n",
    "    best_J: float\n",
    "    best_J_ema: float\n",
    "    final_loss: float\n",
    "    improved: bool\n",
    "    good_tail: bool\n",
    "    config_summary: Dict[str, Any]  # model_type, layers, parameter_scale, etc.\n",
    "\n",
    "########################\n",
    "# 3) Core evaluation   #\n",
    "########################\n",
    "def load_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    with path.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def read_config_summary(trial_dir: Path) -> Dict[str, Any]:\n",
    "    # Try a few common config filenames\n",
    "    out = {\"model_type\": None, \"layers\": None, \"hidden\": None,\n",
    "           \"parameter_scale\": None, \"epochs\": None, \"trial\": trial_dir.name}\n",
    "    # Lightweight parse from path name (fallback)\n",
    "    m = re.search(r\"(MLP|CNN|LSTM)\", trial_dir.name, re.I)\n",
    "    if m: out[\"model_type\"] = m.group(1).upper()\n",
    "    for fname in [\"config.json\", \"config.yaml\", \"train_config.yaml\"]:\n",
    "        p = trial_dir / fname\n",
    "        if p.exists():\n",
    "            try:\n",
    "                if p.suffix == \".json\":\n",
    "                    cfg = json.loads(p.read_text())\n",
    "                else:\n",
    "                    # naive YAML loader to avoid pyyaml dependency\n",
    "                    import yaml  # comment out if you truly can't have it\n",
    "                    cfg = yaml.safe_load(p.read_text())\n",
    "                out.update({k: cfg.get(k) for k in [\"model_type\",\"layers\",\"hidden\",\"parameter_scale\",\"epochs\"] if k in cfg})\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "def evaluate_trial(trial_dir: Path) -> Optional[TrialResult]:\n",
    "    val_path = trial_dir / VAL_LOG\n",
    "    base_path = trial_dir / BASELINE_FILE\n",
    "    if not val_path.exists() or not base_path.exists():\n",
    "        return None\n",
    "\n",
    "    logs = load_jsonl(val_path)\n",
    "    if len(logs) < MIN_EPOCHS:\n",
    "        return None\n",
    "\n",
    "    baseline = json.loads(base_path.read_text())\n",
    "    epochs, losses, Js = [], [], []\n",
    "\n",
    "    for row in logs:\n",
    "        ep = int(row.get(\"epoch\", len(epochs)))\n",
    "        met = row.get(\"metrics\", {})\n",
    "        loss = float(row.get(\"loss\", math.nan))\n",
    "        J = _compute_J(met, baseline)\n",
    "        epochs.append(ep); losses.append(loss); Js.append(J)\n",
    "\n",
    "    J_ema = _ema(Js, EMA_ALPHA)\n",
    "    # choose best by raw J (not EMA), but keep EMA for stability diagnostics\n",
    "    best_idx = int(min(range(len(Js)), key=lambda i: Js[i]))\n",
    "    best_epoch = epochs[best_idx]\n",
    "    best_J, best_J_ema = Js[best_idx], J_ema[best_idx]\n",
    "\n",
    "    # diagnostics: did J meaningfully improve vs early training?\n",
    "    early = Js[min(5, len(Js)-1)]\n",
    "    improved = (early - best_J) / max(early, 1e-6) >= IMPROVEMENT_FLOOR\n",
    "\n",
    "    # diagnostics: tail monotonic-ish check over last 20% epochs (EMA)\n",
    "    tail_start = int(0.8 * len(J_ema))\n",
    "    tail = J_ema[tail_start:]\n",
    "    good_tail = True\n",
    "    for i in range(1, len(tail)):\n",
    "        if tail[i] - tail[i-1] > NONINCR_TOL * max(tail[i-1], 1e-6):\n",
    "            good_tail = False; break\n",
    "\n",
    "    cfg = read_config_summary(trial_dir)\n",
    "    return TrialResult(\n",
    "        trial_dir=str(trial_dir),\n",
    "        best_epoch=best_epoch,\n",
    "        best_J=best_J,\n",
    "        best_J_ema=best_J_ema,\n",
    "        final_loss=float(losses[-1]),\n",
    "        improved=improved,\n",
    "        good_tail=good_tail,\n",
    "        config_summary=cfg\n",
    "    )\n",
    "\n",
    "########################\n",
    "# 4) Batch orchestration\n",
    "########################\n",
    "def scan_and_rank(root: str) -> Dict[str, Any]:\n",
    "    rootp = Path(root)\n",
    "    results: List[TrialResult] = []\n",
    "    for trial in sorted([p for p in rootp.glob(\"**/\") if (p/VAL_LOG).exists()]):\n",
    "        r = evaluate_trial(trial)\n",
    "        if r is not None:\n",
    "            results.append(r)\n",
    "\n",
    "    # Filter out unstable runs first\n",
    "    stable = [r for r in results if r.improved and r.good_tail]\n",
    "    finalists = stable if stable else results  # if nothing stable, fall back\n",
    "\n",
    "    # Rank by best_J, then tail-extremes proxy if you log it (we already folded into J)\n",
    "    finalists.sort(key=lambda r: (r.best_J, r.best_J_ema, r.final_loss))\n",
    "\n",
    "    # Summaries\n",
    "    table = []\n",
    "    for r in finalists:\n",
    "        row = {\n",
    "            \"trial\": Path(r.trial_dir).name,\n",
    "            \"best_epoch\": r.best_epoch,\n",
    "            \"best_J\": round(r.best_J, 6),\n",
    "            \"best_J_ema\": round(r.best_J_ema, 6),\n",
    "            \"final_loss\": round(r.final_loss, 6),\n",
    "            \"improved\": r.improved,\n",
    "            \"good_tail\": r.good_tail,\n",
    "            **{f\"cfg_{k}\": v for k, v in r.config_summary.items()}\n",
    "        }\n",
    "        table.append(row)\n",
    "\n",
    "    best = finalists[0] if finalists else None\n",
    "    return {\n",
    "        \"best\": asdict(best) if best else None,\n",
    "        \"ranked\": table,\n",
    "        \"n_total\": len(results),\n",
    "        \"n_stable\": len(stable),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4618fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse, csv, sys\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--exp_root\", required=True, help=\"Directory containing many trial subfolders\")\n",
    "    ap.add_argument(\"--out_csv\", default=\"auto_select_results.csv\")\n",
    "    ap.add_argument(\"--out_json\", default=\"auto_select_best.json\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    summary = scan_and_rank(args.exp_root)\n",
    "\n",
    "    # CSV table for quick viewing\n",
    "    rows = summary[\"ranked\"]\n",
    "    if rows:\n",
    "        keys = list(rows[0].keys())\n",
    "        with open(args.out_csv, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=keys)\n",
    "            w.writeheader(); w.writerows(rows)\n",
    "\n",
    "    # JSON with winner & counts\n",
    "    with open(args.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[auto_select] scanned={summary['n_total']} stable={summary['n_stable']}\")\n",
    "    if summary[\"best\"]:\n",
    "        print(f\"[auto_select] BEST trial={Path(summary['best']['trial_dir']).name} epoch={summary['best']['best_epoch']} J={summary['best']['best_J']:.4f}\")\n",
    "    else:\n",
    "        print(\"[auto_select] No valid trials found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
