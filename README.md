# dCLIMAD-BA: Differentiable Climate Model Adjustment and Downscaling - Bias Adjustment Only

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.4.1-EE4C2C.svg?style=flat&logo=pytorch)](https://pytorch.org)

A differentiable framework for climate model bias adjustment. This project combines advanced neural architectures with domain-specific climate science knowledge to produce bias-corrected precipitation data from coarse-resolution climate model outputs.

NOTE 1: This code currently only does bias correction, the downscaling model will be available soon! 

NOTE 2: The manuscript for this work is under preparation ğŸ“œ 

## ğŸŒ Overview

Climate models produce valuable projections but at spatial resolutions (25-100km) too coarse for many impact studies. **dCLIMAD-BA** addresses this challenge by:

- **Bias Adjustment**: Corrects systematic biases in climate model outputs using physically-informed transformations
- **Spatial-Temporal Modeling**: Leverages spatial correlations and temporal patterns for enhanced accuracy
- **Multi-Model Support**: Works with CMIP6 climate models and observational datasets (Livneh, GridMET)

## ğŸ—ï¸ Architecture

### Core Models

**SpatioTemporalQM**: Advanced neural architecture with:
   - Temporal encoders (Conv1D, LSTM, Transformer)
   - Spatial attention with geographic awareness
   - Monotone-basis transformations for adjusting biases


### Key Features

- **Monotone Mapping**: Preserves precipitation order relationships
- **Seasonal Neighbors**: LOCA-style spatial correlation modeling
- **Multi-Scale Processing**: Daily to seasonal temporal patterns
- **Physical Constraints**: Non-negative precipitation with trace thresholds

## ğŸ“‹ Requirements

### Environment Setup

```bash
# Clone the repository
git clone https://github.com/kasProg/dCLIMAD-BA.git
cd dCLIMAD-BA

# Create conda environment
conda env create -f env.yml
conda activate dCLIMAD
```

### Key Dependencies

- **Deep Learning**: PyTorch 2.4.1, CUDA 11.8
- **Climate Data**: xarray, netCDF4, rasterio
- **Geospatial**: geopandas, rioxarray, pyproj
- **Scientific**: numpy, scipy, scikit-learn
- **Hydra**: Configuration management
- **Ibicus**: Climate evaluation metrics

## ğŸš€ Quick Start

### 1. Configuration

The project uses **Hydra** configuration management with sweep configs. Main configuration structure:

```
configs/
â”œâ”€â”€ config.yaml          # Main config with defaults
â””â”€â”€ sweep/               # Hyperparameter sweep configurations
    â”œâ”€â”€ conv1d.yaml      # Conv1D temporal encoder experiments
    â”œâ”€â”€ lstm.yaml        # LSTM-based experiments  
    â””â”€â”€ mlp.yaml         # MLP-based experiments
```

Example sweep configuration (`configs/sweep/conv1d.yaml`):
```yaml
# @package _global_
clim: ['access_cm2', 'gfdl_esm4', 'ipsl_cm6a_lr', 'miroc6', 'mpi_esm1_2_lr','mri_esm2_0']
degree: [8, 10]
emph_quantile: [0.5, 0.9]
temp_enc: 'Conv1d'
epochs: 500
layers: 2
```

### 2. Training

#### Single Experiment
```bash
# Using default sweep config (conv1d)
python run_exp.py

# Using specific sweep config
python run_exp.py sweep=lstm

# Override individual parameters
python run_exp.py sweep=conv1d clim=access_cm2 epochs=100 degree=8 emph_quantile=0.5
```

#### Hyperparameter Sweeps
```bash
# Launch sweep with automatic GPU management
python launcher.py

# Use specific sweep configuration
python launcher.py sweep=lstm

# Override sweep parameters
python launcher.py sweep=conv1d clim=access_cm2 epochs=200

# Dry run to see what would be executed
python launcher.py sweep=lstm dry_run=true
```

#### SLURM Batch Jobs
```bash
# Submit to SLURM queue
sbatch slurm1.sbatch

# Monitor job status
squeue -u $USER
```

### 3. Evaluation

#### Single Model Validation
```bash
# Validate specific model run
python run_val.py --run_id <run_id> --base_dir outputs/ 

# Validate with specific validation period
python run_val.py --run_id <run_id> --base_dir outputs/ --val_period 1965,1978
```

#### Batch Validation
```bash
# Validate all models in directory
./run_val_batch.sh outputs/experiment_name/ 1965,1978

# Run in background mode
RUN_IN_BACKGROUND=true ./run_val_batch.sh outputs/experiment_name/ 1965,1978
```

#### Model Selection and Ranking
```bash
# Rank all models by performance metrics
python run_model_selector.py --exp_root outputs/experiment_name/

# Use specific validation period for ranking
python run_model_selector.py --exp_root outputs/experiment_name/ --val_period 1965,1978

# Save results to custom files
python run_model_selector.py --exp_root outputs/experiment_name/ \
    --out_csv my_results.csv --out_json my_best_model.json
```

## ğŸ“ Project Structure

```
dCLIMAD_BA/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.py           # Neural network architectures
â”‚   â””â”€â”€ loss.py            # Climate-specific loss functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loader.py          # Advanced data loading with spatial patches
â”‚   â”œâ”€â”€ helper.py          # Utility functions and time processing
â”‚   â””â”€â”€ process.py         # Data preprocessing and normalization
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ metrics.py         # Climate evaluation metrics
â”œâ”€â”€ config_files/         # Hydra configuration files
â”œâ”€â”€ outputs/              # Model outputs and checkpoints
â”œâ”€â”€ runs/                 # TensorBoard logging
â”œâ”€â”€ slurm/               # HPC batch scripts
â”œâ”€â”€ launcher.py          # Hyperparameter sweep orchestration
â”œâ”€â”€ run_exp.py          # Single experiment training
â”œâ”€â”€ run_val.py          # Model validation
â””â”€â”€ benchmarking.py     # Baseline comparisons
```

## ğŸ”¬ Scientific Features

### Climate-Aware Design

- **Trace Precipitation**: Handles values < 0.254mm appropriately
- **Seasonal Correlations**: Uses time-varying spatial neighbor selection
- **Physical Constraints**: Monotonic transformations preserve order relationships
- **Multi-Scale Temporal**: Processes daily, monthly, and seasonal patterns

### Spatial Processing

- **Haversine Distance**: Geographic distance calculations for spatial relationships
- **Patch-Based Training**: Processes spatial neighborhoods for context
- **Attention Mechanisms**: Geographic-aware positional encoding

### Evaluation Metrics

- **Climate Indices**: Rx1day, Rx5day, CDD, CWD, SDII
- **Extreme Precipitation**: R10mm, R20mm, R95pTOT, R99pTOT
- **Bias Metrics**: Comprehensive bias assessment with baseline comparisons

## ğŸ”§ Advanced Usage

### Custom Model Training

```python
from model.model import SpatioTemporalQM
from data.loader import DataLoaderWrapper

# Initialize model
model = SpatioTemporalQM(
    f_in=9,                    # Input features
    f_model=64,                # Hidden dimensions
    heads=4,                   # Attention heads
    degree=8,                  # Transform complexity
    transform_type='monotone'  # Physical constraints
)

# Load data with spatial patches
loader = DataLoaderWrapper(
    clim='access_cm2',
    scenario='historical',
    ref='livneh',
    period=[1950, 1980],
    # ... other parameters
)

# Get spatial dataloader
dataloader = loader.get_spatial_dataloader(K=16)  # 16 neighbors
```

### Hyperparameter Sweeps

The launcher supports automatic GPU management and job distribution:

```bash
# Run sweep with dry-run mode
python launcher.py sweep=lstm clim=access_cm2 epochs=100 dry_run=true

# Full execution across available GPUs
python launcher.py sweep=conv1d clim=['access_cm2','gfdl_esm4'] epochs=400
```

### Model Selection

Automated model ranking based on climate metrics:

```python
from demo_model_selector import scan_and_rank

# Evaluate all models in directory
results = scan_and_rank(
    root='outputs/experiment_suite',
    val_period='1965,1978'
)

print(f"Best model: {results['best']['trial_dir']}")
print(f"Metrics: J={results['best']['best_J']:.4f}")
```

## ğŸ“Š Performance Monitoring

### TensorBoard Integration

```bash
tensorboard --logdir runs/
```

### GPU Monitoring

```bash
# Monitor GPU usage during training
./auto_eval.sh

# Check job status
squeue -u $USER
```

## ğŸ¯ Applications

- **Climate Impact Studies**: High-resolution precipitation for hydrology
- **Agricultural Planning**: Crop modeling with bias-corrected climate data  
- **Water Resource Management**: Streamflow and drought analysis
- **Urban Planning**: Infrastructure design under climate change

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@software{dclimad_ba_2025,
  title={dCLIMAD-BA: Differentiable Climate Model Adjustment and Downscaling - Bias Adjustment Only},
  author={[Kamlesh Sawadekar]},
  year={2024},
  url={https://github.com/kasProg/dCLIMAD-BA},
  version={1.0}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“§ Contact

- **Primary Contact**: kas7897@psu.edu
- **Issues**: [GitHub Issues](https://github.com/kasProg/dCLIMAD-BA/issues)
- **Discussions**: [GitHub Discussions](https://github.com/kasProg/dCLIMAD-BA/discussions)


## ğŸ™ Acknowledgments

- CMIP6 climate modeling community
- Livneh and GridMET observational datasets
- PyTorch and scientific Python ecosystem
- High-performance computing resources

## ğŸ”— Related Work

- [Ibicus](https://github.com/btschwertfeger/Ibicus): Climate bias adjustment toolkit
- [LOCA](https://loca.ucsd.edu/): Localized Constructed Analogs downscaling
- [DeepSD](https://github.com/jjgomezcadenas/DeepSD): Deep learning statistical downscaling

---

**Note**: This is a research project under active development. Please report issues and contribute to make it better for the climate science community! ğŸŒ
